{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U-Net and Res-Unet tf2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"code","metadata":{"id":"SYkAbHbfcku-"},"source":["%load_ext autoreload"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2L_yKE1IgpA0"},"source":["%autoreload # When utils.py is updated\n","from utils_unet_resunet import *\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","root_path = 'your_directory' "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kylt2BueckvP"},"source":["# Define data type (L8-Landsat8, S2-Sentinel2, S1-Sentinel1)\n","img_type = 'L8'\n","\n","if img_type = 'L8':\n","    # Load images\n","    ref_2019 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2019.tif').astype('float32') # actual 2019\n","    opt_2018 = load_tif_image(root_path+'New_Images/Landsat8/'+'cut_land8_2018.tif').astype('float32')   \n","    opt_2019 = load_tif_image(root_path+'New_Images/Landsat8/'+'cut_land8_2019.tif').astype('float32')\n","\n","    # Resize images\n","    opt_2018 = resize_image(opt_2018.copy(), ref_2019.shape[0], ref_2019.shape[1])\n","    opt_2019 = resize_image(opt_2019.copy(), ref_2019.shape[0], ref_2019.shape[1])  \n","\n","    # Filter outliers\n","    opt_2018 = filter_outliers(opt_2018.copy()) \n","    opt_2019 = filter_outliers(opt_2019.copy())\n","    \n","    image_stack = np.concatenate((opt_2018, opt_2019), axis=-1)\n","    print('landsat_resize:', image_stack.shape)\n","    del opt_2018, opt_2019\n","\n","if img_type = 'S2':\n","    # Load images\n","    sent2_2018_1 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2018_10m_b2348.tif').astype('float32')\n","    sent2_2018_2 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2018_20m_b5678a1112.tif').astype('float32')\n","    \n","    # Resize bands of 20m\n","    sent2_2018_2 = resize_image(sent2_2018_2.copy(), sent2_2018_1.shape[0], sent2_2018_1.shape[1])\n","    sent2_2018 = np.concatenate((sent2_2018_1, sent2_2018_2), axis=-1)\n","    del sent2_2018_1, sent2_2018_2\n","    \n","    sent2_2019_1 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2019_10m_b2348.tif').astype('float32')\n","    sent2_2019_2 = load_tif_image(root_path+'New_Images/Sentinel2/'+'2019_20m_b5678a1112.tif').astype('float32')   \n","    \n","    # Resize bands of 20m\n","    sent2_2019_2 = resize_image(sent2_2019_2.copy(), sent2_2019_1.shape[0], sent2_2019_1.shape[1])\n","    sent2_2019 = np.concatenate((sent2_2019_1, sent2_2019_2), axis=-1)\n","    del sent2_2019_1, sent2_2019_2\n","    \n","    # Filter outliers\n","    sent2_2018 = filter_outliers(sent2_2018.copy()) \n","    sent2_2019 = filter_outliers(sent2_2019.copy()) \n","    \n","    image_stack = np.concatenate((sent2_2018, sent2_2019), axis=-1)\n","    print('Image stack:', image_stack.shape)\n","    del sent2_2018, sent2_2019\n","\n","if img_type = 'S1':\n","    # Load images\n","    sar_2018_vh = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vh_2018.tif').astype('float32'), axis = -1)\n","    sar_2018_vv = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vv_2018.tif').astype('float32'), axis = -1)\n","    sar_2019_vh = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vh_2019.tif').astype('float32'), axis = -1)\n","    sar_2019_vv = np.expand_dims(load_SAR_image(root_path+'New_Images/Sentinel1/'+'cut_sent1_vv_2019.tif').astype('float32'), axis = -1)\n","    \n","    sar_2018 = np.concatenate((sar_2018_vh, sar_2018_vv), axis=-1)\n","    sar_2019 = np.concatenate((sar_2019_vh, sar_2019_vv), axis=-1)\n","    del sar_2018_vh, sar_2018_vv, sar_2019_vh, sar_2019_vv\n","    \n","    # Filter outliers\n","    sar_2018 = filter_outliers(sar_2018.copy()) \n","    sar_2019 = filter_outliers(sar_2019.copy()) \n","\n","    image_stack = np.concatenate((sar_2018, sar_2019), axis=-1)\n","    print('Image stack:', image_stack.shape)\n","    del sar_2018, sar_2019\n","\n","# load references     \n","# Load current reference \n","ref_2019 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2019.tif').astype('float32') # actual 2019\n","# Load past references\n","#past_ref = np.load(root_path+'New_Images/References/past_ref_and_clouds.npy').astype('float32')\n","past_ref1 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_1988_2007.tif').astype('float32') # 1988_2007\n","past_ref2 = load_tif_image(root_path+'New_Images/References/res_10m/r10m_def_2008_2018.tif').astype('float32') # 2008_2018\n","clouds_2018 = load_tif_image(root_path+'New_Images/References/cut_b10_2018.tif').astype('float32')\n","clouds_2018 = resize_image(np.expand_dims(clouds_2018.copy(), axis = -1), ref_2019.shape[0], ref_2019.shape[1])\n","clouds_2018 = binary_mask_cloud(clouds_2018.copy(), 50)\n","clouds_2019 = load_tif_image(root_path+'New_Images/References/cut_b10_2019.tif').astype('float32') \n","clouds_2019 = resize_image(np.expand_dims(clouds_2019.copy(), axis = -1), ref_2019.shape[0], ref_2019.shape[1])\n","clouds_2019 = binary_mask_cloud(clouds_2019.copy(), 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1PrXGBIiimC0"},"source":["# Create label mask\n","past_ref = past_ref1 + past_ref2 + clouds_2018 + clouds_2019\n","past_ref[past_ref>=1] = 1\n","buffer = 2\n","final_mask1 = mask_no_considered(ref_2019, buffer, past_ref)\n","del past_ref1, past_ref2, clouds_2018, clouds_2019\n","\n","lim_x = 10000\n","lim_y = 7000\n","image_stack = image_stack[:lim_x, :lim_y, :]\n","final_mask1 = final_mask1[:lim_x, :lim_y]\n","ref_2019 = ref_2019[:lim_x, :lim_y]\n","\n","h_, w_, channels = image_stack.shape\n","print('image stack size: ', image_stack.shape)\n","\n","# Normalization\n","type_norm = 1\n","image_array = normalization(image_stack.copy(), type_norm)\n","print(np.min(image_array), np.max(image_array))\n","del image_stack\n","\n","# Print pertengate of each class (whole image)\n","print('Total no-deforestaion class is {}'.format(len(final_mask1[final_mask1==0])))\n","print('Total deforestaion class is {}'.format(len(final_mask1[final_mask1==1])))\n","print('Total past deforestaion class is {}'.format(len(final_mask1[final_mask1==1])))\n","print('Percentage of deforestaion class is {:.2f}'.format((len(final_mask1[final_mask1==1])*100)/len(final_mask1[final_mask1==0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knelmZc2HRTO"},"source":["# Create tile mask\n","mask_tiles = create_mask(final_mask1.shape[0], final_mask1.shape[1], grid_size=(5, 4))\n","image_array = image_array[:mask_tiles.shape[0], :mask_tiles.shape[1],:]\n","final_mask1 = final_mask1[:mask_tiles.shape[0], :mask_tiles.shape[1]]\n","\n","print('mask: ',mask_tiles.shape)\n","print('image stack: ', image_array.shape)\n","print('ref :', final_mask1.shape)\n","#plt.imshow(mask_tiles)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gExq8XOCckvb"},"source":["plt.figure(figsize=(10,5))\n","plt.imshow(final_mask1, cmap = 'jet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OKaXQmmGoxLz"},"source":["# Define tiles for training, validation, and test sets\n","tiles_tr = [1,3,5,8,11,13,14,20]\n","tiles_val = [6,19]\n","tiles_ts = (list(set(np.arange(20)+1)-set(tiles_tr)-set(tiles_val)))\n","\n","mask_tr_val = np.zeros((mask_tiles.shape)).astype('float32')\n","# Training and validation mask\n","for tr_ in tiles_tr:\n","    mask_tr_val[mask_tiles == tr_] = 1\n","\n","for val_ in tiles_val:\n","    mask_tr_val[mask_tiles == val_] = 2\n","\n","mask_amazon_ts = np.zeros((mask_tiles.shape)).astype('float32')\n","for ts_ in tiles_ts:\n","    mask_amazon_ts[mask_tiles == ts_] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QI8Gc-NQrr44"},"source":["# Create ixd image to extract patches\n","overlap = 0.7\n","patch_size = 128\n","batch_size = 32\n","im_idx = create_idx_image(final_mask1)\n","patches_idx = extract_patches(im_idx, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1,patch_size, patch_size)\n","patches_mask = extract_patches(mask_tr_val, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1, patch_size, patch_size)\n","del im_idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1V39Gf4owRBa"},"source":["# Selecting index trn val and test patches idx\n","idx_trn = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==patch_size**2))\n","idx_val = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==2*patch_size**2))\n","del patches_mask\n","\n","patches_idx_trn = patches_idx[idx_trn]\n","patches_idx_val = patches_idx[idx_val]\n","del idx_trn, idx_val\n","\n","print('Number of training patches:  ', len(patches_idx_trn), 'Number of validation patches', len(patches_idx_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycpxzOJblJvr"},"source":["# Extract patches with at least 2% of deforestation class\n","X_train = retrieve_idx_percentage(final_mask1, patches_idx_trn, pertentage = 2)\n","X_valid = retrieve_idx_percentage(final_mask1, patches_idx_val, pertentage = 2)\n","print(X_train.shape, X_valid.shape)\n","del patches_idx_trn, patches_idx_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpchvB9nZOmC"},"source":["def batch_generator(batches, image, reference, target_size, number_class):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    image = image.reshape(-1, image.shape[-1])\n","    reference = reference.reshape(final_mask1.shape[0]*final_mask1.shape[1])\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_x = np.squeeze(batch_x.astype('int64'))\n","        #print(batch_x.shape)\n","        batch_img = np.zeros((batch_x.shape[0], target_size, target_size, image.shape[-1]))\n","        batch_ref = np.zeros((batch_x.shape[0], target_size, target_size, number_class))\n","        \n","        for i in range(batch_x.shape[0]):\n","            if np.random.rand()>0.5:\n","                batch_x[i] = np.rot90(batch_x[i], 1)\n","            batch_img[i] = image[batch_x[i]] \n","            batch_ref[i] = tf.keras.utils.to_categorical(reference[batch_x[i]] , number_class)\n","                       \n","        yield (batch_img, batch_ref)\n","\n","train_datagen = ImageDataGenerator(horizontal_flip = True,\n","                                   vertical_flip = True)\n","valid_datagen = ImageDataGenerator(horizontal_flip = True, \n","                                   vertical_flip = True)\n","\n","y_train = np.zeros((len(X_train)))\n","y_valid = np.zeros((len(X_valid)))\n","\n","train_gen = train_datagen.flow(np.expand_dims(X_train, axis = -1), y_train,\n","                              batch_size=batch_size,\n","                              shuffle=True)\n","\n","valid_gen = valid_datagen.flow(np.expand_dims(X_valid, axis = -1), y_valid,\n","                              batch_size=batch_size,\n","                              shuffle=False)\n","\n","number_class = 3\n","train_gen_crops = batch_generator(train_gen, image_array, final_mask1, patch_size, number_class)\n","valid_gen_crops = batch_generator(valid_gen, image_array, final_mask1, patch_size, number_class)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfJK-atSgFTG"},"source":["exp = 1\n","path_exp = root_path+'experiments/exp'+str(exp)\n","path_models = path_exp+'/models'\n","path_maps = path_exp+'/pred_maps'\n","\n","if not os.path.exists(path_exp):\n","    os.makedirs(path_exp)   \n","if not os.path.exists(path_models):\n","    os.makedirs(path_models)   \n","if not os.path.exists(path_maps):\n","    os.makedirs(path_maps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ol_1Ci3TlbrM"},"source":["# Define model\r\n","input_shape = (patch_size, patch_size, channels)\r\n","nb_filters = [32, 64, 128]\r\n","\r\n","method = 'unet'\r\n","if method == 'unet':\r\n","   model = build_unet(input_shape, nb_filters, number_class)\r\n","\r\n","if method == 'resunet':\r\n","   model = build_resunet(input_shape, nb_filters, number_class)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4Ql8N-flPbi"},"source":["# Parameters of the model\r\n","weights = [0.2, 0.8, 0]\r\n","adam = Adam(lr = 1e-3 , beta_1=0.9)\r\n","loss = weighted_categorical_crossentropy(weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"568DB3nZLrHC"},"source":["time_tr = []\n","times = 5  \n","for tm in range(0,times):\n","    print('time: ', tm)\n","    \n","    model.compile(optimizer=adam, loss=loss, metrics=['accuracy'])\n","    model.summary()\n","\n","    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min')\n","    checkpoint = ModelCheckpoint(path_models+ '/' + method +'_'+str(tm)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","    lr_reduce = ReduceLROnPlateau(factor=0.9, min_delta=0.0001, patience=5, verbose=1)\n","    callbacks_list = [earlystop, checkpoint]\n","    # train the model\n","    start_training = time.time()\n","    history = model.fit_generator(train_gen_crops,\n","                              steps_per_epoch=len(X_train)*3//train_gen.batch_size,\n","                              validation_data=valid_gen_crops,\n","                              validation_steps=len(X_valid)*3//valid_gen.batch_size,\n","                              epochs=100,\n","                              callbacks=callbacks_list)\n","    end_training = time.time() - start_training\n","    time_tr.append(end_training)\n","time_tr_array = np.asarray(time_tr)\n","# Save training time\n","np.save(path_exp+'/metrics_tr.npy', time_tr_array)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMem2rkfpL-g"},"source":["# Test loop\n","time_ts = []\n","n_pool = 3\n","n_rows = 5\n","n_cols = 4\n","rows, cols = image_array.shape[:2]\n","pad_rows = rows - np.ceil(rows/(n_rows*2**n_pool))*n_rows*2**n_pool\n","pad_cols = cols - np.ceil(cols/(n_cols*2**n_pool))*n_cols*2**n_pool\n","print(pad_rows, pad_cols)\n","\n","npad = ((0, int(abs(pad_rows))), (0, int(abs(pad_cols))), (0, 0))\n","image1_pad = np.pad(image_array, pad_width=npad, mode='reflect')\n","\n","h, w, c = image1_pad.shape\n","patch_size_rows = h//n_rows\n","patch_size_cols = w//n_cols\n","num_patches_x = int(h/patch_size_rows)\n","num_patches_y = int(w/patch_size_cols)\n","\n","input_shape=(patch_size_rows,patch_size_cols, c)\n","\n","if method == 'unet':\n","   new_model = unet(input_shape, nb_filters, number_class)\n","\n","if method == 'resunet':\n","   new_model = build_resunet(input_shape, nb_filters, number_class)\n","\n","for tm in range(0,times):\n","    print('time: ', tm)\n","    model = load_model(path_models+ '/' + method +'_'+str(tm)+'.h5', compile=False)\n","    \n","    for l in range(1, len(model.layers)):\n","        new_model.layers[l].set_weights(model.layers[l].get_weights())\n","    \n","    start_test = time.time()\n","    patch_t = []\n","    \n","    for i in range(0,num_patches_y):\n","        for j in range(0,num_patches_x):\n","            patch = image1_pad[patch_size_rows*j:patch_size_rows*(j+1), patch_size_cols*i:patch_size_cols*(i+1), :]\n","            predictions_ = new_model.predict(np.expand_dims(patch, axis=0))\n","            del patch \n","            patch_t.append(predictions_[:,:,:,1])\n","            del predictions_\n","    end_test =  time.time() - start_test\n","    patches_pred = np.asarray(patch_t).astype(np.float32)\n","\n","    prob_recontructed = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred)\n","    np.save(path_maps+'/'+'prob_'+str(tm)+'.npy',prob_recontructed) \n","\n","    time_ts.append(end_test)\n","    del prob_recontructed, model, patches_pred\n","time_ts_array = np.asarray(time_ts)\n","# Save test time\n","np.save(path_exp+'/metrics_ts.npy', time_ts_array)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ehh68acZW2lR"},"source":["# Compute mean of the tm predictions maps\n","prob_rec = np.zeros((image1_pad.shape[0],image1_pad.shape[1], times))\n","\n","for tm in range (0, times):\n","    print(tm)\n","    prob_rec[:,:,tm] = np.load(path_maps+'/'+'prob_'+str(tm)+'.npy').astype(np.float32)\n","\n","mean_prob = np.mean(prob_rec, axis = -1)\n","np.save(path_maps+'/prob_mean.npy', mean_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVDldxUWckvg"},"source":["# Plot mean map and reference\n","fig = plt.figure(figsize=(15,10))\n","ax1 = fig.add_subplot(121)\n","plt.title('Prediction')\n","ax1.imshow(mean_prob, cmap ='jet')\n","ax1.axis('off')\n","\n","ax2 = fig.add_subplot(122)\n","plt.title('Reference')\n","ax2.imshow(ref_2019, cmap ='jet')\n","ax2.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4P8pVKDxW6Lh"},"source":["# Computing metrics\n","mean_prob = mean_prob[:final_mask1.shape[0], :final_mask1.shape[1]]\n","ref1 = np.ones_like(final_mask1).astype(np.float32)\n","\n","ref1 [final_mask1 == 2] = 0\n","TileMask = mask_amazon_ts * ref1\n","GTTruePositives = final_mask1==1\n","    \n","Npoints = 50\n","Pmax = np.max(mean_prob[GTTruePositives * TileMask ==1])\n","ProbList = np.linspace(Pmax,0,Npoints)\n","    \n","metrics_ = matrics_AA_recall(ProbList, mean_prob, final_mask1, mask_amazon_ts, 625)\n","np.save(path_exp+'/acc_metrics.npy',metrics_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DB-vr1sq6PwK"},"source":["# Complete NaN values\n","metrics_copy = metrics_.copy()\n","metrics_copy = complete_nan_values(metrics_copy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HNG_I2cW8JF"},"source":["# Comput Mean Average Precision (mAP) score \n","Recall = metrics_copy[:,0]\n","Precision = metrics_copy[:,1]\n","AA = metrics_copy[:,2]\n","    \n","DeltaR = Recall[1:]-Recall[:-1]\n","AP = np.sum(Precision[:-1]*DeltaR)\n","print('mAP', AP)\n","\n","# Plot Recall vs. Precision curve\n","plt.close('all')\n","plt.plot(metrics_copy[:,0],metrics_copy[:,1])\n","plt.plot(metrics_copy[:,0],metrics_copy[:,2])\n","plt.grid()"],"execution_count":null,"outputs":[]}]}